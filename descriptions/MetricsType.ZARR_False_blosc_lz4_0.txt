A provenance file created using the yProv4ML library (version 0), following the W3C prov schema (http://www.w3.org/2000/10/XMLSchema#), and creating a user namespace at www.example.org. The file contains a machine learning process with run_id: 4, started by user gabriele.padovani, with python 3.11.11 (main, Dec 11 2024, 16:28:39) [GCC 11.2.0], and named MetricsType.ZARR_False_blosc_lz4. 
The entire experiment was run in a None environment, The experiment was scheduled at 2025-06-04 11:35:08 and it finished at 2025-06-04 11:36:48, for a total of 99.61 seconds. 
The model was trained for 8 epochs,each epoch consisting in the passthrough of 10000 samples, with batch size 32. The model was saved 6 times, in the checkpoints prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/mnist_model_final/mnist_model_final_0.pth, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/mnist_model_version_0/mnist_model_version_0_0.pth, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/mnist_model_version_1/mnist_model_version_1_0.pth, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/mnist_model_version_2/mnist_model_version_2_0.pth, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/mnist_model_version_3/mnist_model_version_3_0.pth, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/mnist_model_version_4/mnist_model_version_4_0.pth. with the final version being mnist_model_final. The final model has a total of 7850 parameters, and the footprint on the memory is of 0.03 Mb. The datasets used for the training of the model are: train_dataset with 10000 samples, 32 batch size and 313 steps. 
The user saved a set of parameters from the process, including: execution_start_time, model_name, total_params, memory_of_model, total_memory_load_of_model, execution_end_timeA set of metrics have been collected from the process, in particular in the contexts EVALUATION_GR0.zarr, EVALUATION, TRAINING_GR0.zarr, TRAINING, these metrics are MSE_train_Context.TRAINING, MSE_train2_Context.TRAINING, MSE_train3_Context.TRAINING, MSE_train4_Context.TRAINING, MSE_train5_Context.TRAINING, Indices_Context.TRAINING, MSE_test_Context.EVALUATION, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/metrics/MSE_train_Context.TRAINING_GR0.zarr, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/metrics/MSE_train2_Context.TRAINING_GR0.zarr, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/metrics/MSE_train3_Context.TRAINING_GR0.zarr, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/metrics/MSE_train4_Context.TRAINING_GR0.zarr, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/metrics/MSE_train5_Context.TRAINING_GR0.zarr, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/metrics/Indices_Context.TRAINING_GR0.zarr, prov/MetricsType.ZARR_False_blosc_lz4_4/artifacts/metrics/MSE_test_Context.EVALUATION_GR0.zarr. 