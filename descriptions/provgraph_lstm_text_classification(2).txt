A provenance file created using the yProv4ML library (version 0), following the W3C prov schema (http://www.w3.org/2000/10/XMLSchema#), and creating a user namespace at www.example.org. The file contains a machine learning process with run_id: 0, started by user lelepado, with python 3.10.4 (main, Mar 31 2022, 08:41:55) [GCC 7.5.0], and named lstm_text_classification. 
The entire experiment was run in a None environment, The experiment was scheduled at 2025-03-13 16:25:21 and it finished at 2025-03-13 16:25:36, for a total of 15.47 seconds. 
The model was trained for 12 epochs,each epoch consisting in the passthrough of 800 samples, with batch size 32. The model was saved 1 times, in the checkpoints prov/lstm_text_classification_0/artifacts/lstm_text_classifier_final/lstm_text_classifier_final_0.pth. with the final version being lstm_text_classifier_final. The final model has a total of 4302594 parameters, and the footprint on the memory is of 17.21 Mb. The datasets used for the training of the model are: train_dataset with 800 samples, 32 batch size and 25 steps; val_dataset with 200 samples, 32 batch size and 7 steps. 
The user saved a set of parameters from the process, including: execution_start_time, optimizer, loss_fn, model_name, total_params, memory_of_model, total_memory_load_of_model, execution_end_timeA set of metrics have been collected from the process, in particular in the contexts VALIDATION, TRAINING, these metrics are gpu_power_usage_Context.TRAINING, ram_power_Context.TRAINING, gpu_temperature_Context.TRAINING, cpu_energy_Context.TRAINING, gpu_energy_Context.TRAINING, cpu_usage_Context.TRAINING, energy_consumed_Context.TRAINING, gpu_power_Context.TRAINING, memory_usage_Context.TRAINING, disk_usage_Context.TRAINING, ram_energy_Context.TRAINING, emissions_Context.TRAINING, Loss_Context.TRAINING, emissions_rate_Context.TRAINING, gpu_memory_usage_Context.TRAINING, Loss_Context.VALIDATION, cpu_power_Context.TRAINING, gpu_usage_Context.TRAINING. 